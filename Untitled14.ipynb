{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDhlTPNgPSbo",
        "outputId": "45031180-507c-4ad7-9970-15f9dd8902fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDB dataset\n",
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrg_YqypTJXR",
        "outputId": "16da79d7-f77c-4a1e-8dc7-276ce413d6a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the reviews\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in word_tokenize(x.lower()) if word.isalnum() and word not in stop_words]))\n",
        "\n",
        "# Prepare labels\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['review']\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7feLp9bKTVXB",
        "outputId": "6995e151-7c66-46a1-9e85-de7f03601019"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 40000\n",
            "Test samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Bag of Words Model\n",
        "count_vectorizer = CountVectorizer()\n",
        "X_train_bow = count_vectorizer.fit_transform(X_train)\n",
        "X_test_bow = count_vectorizer.transform(X_test)\n",
        "nb_model_bow = MultinomialNB()\n",
        "nb_model_bow.fit(X_train_bow, y_train)\n",
        "\n",
        "# Train TF-IDF Model\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "nb_model_tfidf = MultinomialNB()\n",
        "nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train N-gram Model\n",
        "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "X_train_ngram = ngram_vectorizer.fit_transform(X_train)\n",
        "X_test_ngram = ngram_vectorizer.transform(X_test)\n",
        "nb_model_ngram = MultinomialNB()\n",
        "nb_model_ngram.fit(X_train_ngram, y_train)\n",
        "\n",
        "# Tokenize text for Word2Vec and FastText models\n",
        "X_train_tokenized = [word_tokenize(text.lower()) for text in X_train]\n",
        "X_test_tokenized = [word_tokenize(text.lower()) for text in X_test]\n",
        "\n",
        "# Train Word2Vec Model\n",
        "word2vec_model = Word2Vec(sentences=X_train_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
        "X_train_w2v = np.array([np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0) for tokens in X_train_tokenized])\n",
        "X_test_w2v = np.array([np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0) for tokens in X_test_tokenized])\n"
      ],
      "metadata": {
        "id": "vv7oUAgvTXzh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train FastText Model\n",
        "fasttext_model = FastText(sentences=X_train_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
        "X_train_ft = np.array([np.mean([fasttext_model.wv[word] for word in tokens if word in fasttext_model.wv], axis=0) for tokens in X_train_tokenized])\n",
        "X_test_ft = np.array([np.mean([fasttext_model.wv[word] for word in tokens if word in fasttext_model.wv], axis=0) for tokens in X_test_tokenized])\n"
      ],
      "metadata": {
        "id": "PNo3cWo8Tf1g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained models\n",
        "joblib.dump(nb_model_bow, 'nb_model_bow.pkl')\n",
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
        "joblib.dump(ngram_vectorizer, 'ngram_vectorizer.pkl')\n",
        "joblib.dump(word2vec_model, 'word2vec_model.pkl')\n",
        "joblib.dump(fasttext_model, 'fasttext_model.pkl')\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(count_vectorizer, 'count_vectorizer.pkl')\n",
        "\n",
        "print(\"Models and vectorizer saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc8T-pDdTh8t",
        "outputId": "836b74c7-79dc-48c7-aae5-352d3dff88b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models and vectorizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved models and vectorizer\n",
        "nb_model_bow = joblib.load('nb_model_bow.pkl')\n",
        "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "ngram_vectorizer = joblib.load('ngram_vectorizer.pkl')\n",
        "word2vec_model = joblib.load('word2vec_model.pkl')\n",
        "fasttext_model = joblib.load('fasttext_model.pkl')\n",
        "count_vectorizer = joblib.load('count_vectorizer.pkl')\n",
        "\n",
        "print(\"Models and vectorizer loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdUjfNHfTj1E",
        "outputId": "13b534d9-6d58-4f21-db1c-5587a34ceedd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models and vectorizer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "def run_sentiment_analysis(sample_text):\n",
        "    # Prepare input for models\n",
        "    bow_vector = count_vectorizer.transform([sample_text])\n",
        "    tfidf_vector = tfidf_vectorizer.transform([sample_text])\n",
        "    ngram_vector = ngram_vectorizer.transform([sample_text])\n",
        "\n",
        "    # Word2Vec and FastText require the text to be tokenized\n",
        "    tokens = word_tokenize(sample_text.lower())\n",
        "    w2v_vector = np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0)\n",
        "    ft_vector = np.mean([fasttext_model.wv[word] for word in tokens if word in fasttext_model.wv], axis=0)\n",
        "\n",
        "    # Predictions\n",
        "    predictions = {\n",
        "        'Naive Bayes (BoW)': nb_model_bow.predict(bow_vector)[0],\n",
        "        'Naive Bayes (TF-IDF)': nb_model_tfidf.predict(tfidf_vector)[0],  # Assuming nb_model_tfidf is defined\n",
        "        'Naive Bayes (N-gram)': nb_model_ngram.predict(ngram_vector)[0],  # Assuming nb_model_ngram is defined\n",
        "        'Word2Vec': 1 if not np.isnan(w2v_vector).any() else None,  # Return None if NaN\n",
        "        'FastText': 1 if not np.isnan(ft_vector).any() else None,  # Return None if NaN\n",
        "    }\n",
        "\n",
        "    # Filter out None values for mode calculation\n",
        "    valid_predictions = [pred for pred in predictions.values() if pred is not None]\n",
        "\n",
        "    # Final output: majority vote\n",
        "    if valid_predictions:\n",
        "        # Access the mode value directly using .mode, handle scalar and array cases\n",
        "        final_prediction = mode(valid_predictions).mode\n",
        "        final_prediction = final_prediction[0] if isinstance(final_prediction, np.ndarray) else final_prediction\n",
        "    else:\n",
        "        final_prediction = None  # If no valid predictions, set to None\n",
        "\n",
        "    return predictions, final_prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "wqlOD-wpTlw-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "sample_text = \"This movie was fantastic! I loved it.\"\n",
        "predictions, final_output = run_sentiment_analysis(sample_text)\n",
        "\n",
        "print(\"Predictions from each model:\")\n",
        "for model, pred in predictions.items():\n",
        "    if pred is not None:\n",
        "        print(f\"{model}: {'Positive' if pred == 1 else 'Negative'}\")\n",
        "    else:\n",
        "        print(f\"{model}: No Prediction\")\n",
        "\n",
        "if final_output is not None:\n",
        "    print(f\"\\nFinal predicted sentiment: {'Positive' if final_output == 1 else 'Negative'}\")\n",
        "else:\n",
        "    print(\"\\nFinal prediction could not be made.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiBVYICATpJf",
        "outputId": "40b4bd3c-8734-42ee-b5cd-c143c9767104"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from each model:\n",
            "Naive Bayes (BoW): Positive\n",
            "Naive Bayes (TF-IDF): Positive\n",
            "Naive Bayes (N-gram): Positive\n",
            "Word2Vec: Positive\n",
            "FastText: Positive\n",
            "\n",
            "Final predicted sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Suov6dX8g-74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}